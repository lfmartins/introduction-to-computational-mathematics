{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPUBnC8dH/oODlOGIm8UmJS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lfmartins/introduction-to-computational-mathematics/blob/main/14-odesandforwardeuler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Differential Equations\n",
        "\n",
        "Differential equations are equations that are composed of derivatives of functions and functions. Since it's an equation we know that '$=$' present and the derivatives are with respect to an independent variable, e.g. $t$, $x$. If we only have one independent variable in our solution then we say that this is and ordinary differential equation (ODE).\n",
        "\n",
        "Here are a few examples:\n",
        "\n",
        "*  ${dy\\over dt} =cy,\\qquad c=$constant\n",
        "*  ${dy\\over dx} = x^2-2x$\n",
        "\n",
        "*  $m{d^2y\\over dt^2}+ \\beta{dy\\over dt}+gy=0$\n",
        "\n",
        "In MTH 286, we spend time learning methods for analytical solutions to these equations. These solutions are functions with respect to the independent variable. General solutions for the above equations are the following:\n",
        "\n",
        "*  $y = Ae^{ct}$\n",
        "*  $y = {1\\over3}x^3-x^2 + C$\n",
        "*  $y=e^{pt}(A\\cos(\\omega t)+B\\sin(\\omega t))$ or $Ae^{p_1t}+Be^{p_2t}$ or $(A+Bt)e^{pt}$\n",
        "\n",
        "The constants $A,B,C$ are determined by the initial conditions of the differential equation. These solutions satisfy the equations that we listed above. For example, in the first equation\n",
        "\n",
        "$${dy \\over dt}={d \\over dt}(Ae^{ct})=cAe^{ct}=cy$$\n",
        "\n",
        "\n",
        "To deal with $A$, we have an initial condition, for example $y(0)=2$. So for our general solution $y(0)=Ae^{c\\cdot0}=A\\cdot1=A=2$. So $A=2$ and the unique solution is $y(t)=2e^{ct}$, which satisfies the ODE ${dy\\over dt}=cy, y(0)=2$.\n",
        "\n",
        "However, this approach is limited to differential equations that follow a certain form. Most times we cannot develop an analytical solution to a differential equation. \n",
        "\n",
        "\n",
        "Instead, we will learn to use numerical approximations to generate approximate solutions. This approach allows us a lot of flexibility, with the caveat that we now need to keep in mind error associated with approximation.\n"
      ],
      "metadata": {
        "id": "jAwavoLHZd6v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Forward Euler\n",
        "\n",
        "One of the most basic (and useful) methods to use for this process is Forward Euler. We will first deal with first-order, initial value problems that are in normal form:\n",
        "\n",
        "$${dy\\over dt}=f(y,t), \\qquad y(0)=y_0$$\n",
        "\n",
        "Given a general point $t_i$, we start by treating the derivative on the left side using a forward difference approximation\n",
        "\n",
        "$${dy\\over dt}\\approx \\frac{y(t_{i+1})-y(t_{i})}{h}=\\frac{y_{i+1}-y_{i}}{h}$$\n",
        "\n",
        "where $y(t_i)=y_i$ is the numerical solution at $t_i$. Note that $t_{i+1}=t_i+h$\n",
        "\n",
        "If we're starting from an initial value or an approximation at timestep $t_i$, then we can use this approximation to the derivative to predict at the next timestep \n",
        "$$\\frac{y_{i+1}-y_{i}}{h}=f(t_i,y_i)$$\n",
        "$$\\frac{y_{i+1}}{h}=\\frac{y_{i}}{h}+f(t_i,y_i)$$\n",
        "$$â‡’ y_{i+1}=y_{i}+hf(t_i,y_i)$$\n",
        "\n",
        "Forward Euler advances the solution from the initial value using a forward difference approximation to the derivative\n",
        "\n",
        "**<center>Forward Euler</center>**\n",
        "$$y_{i+1}=y_{i}+hf(t_i,y_i),\\qquad y(0)=y_0$$\n",
        "\n",
        "To understand how Forard Euler works, we are going to examine this with a very simple ODE:\n",
        "\n",
        "$$\\frac{dy}{dt}=y,\\qquad y(0)=1.0$$\n",
        "\n",
        "Why such a simple ODE? Well, we know its analytical solution is $y(t)=e^{t}$, so we can compare the accuracy of our methods."
      ],
      "metadata": {
        "id": "xc3JbJ5VZiof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def forwardEuler(y,f,h,t):\n",
        "  ynew=y+h*f(t,y)\n",
        "  return ynew\n",
        "def fun(t,y):\n",
        "  f=y\n",
        "  return y\n",
        "\n",
        "nT=5 #number of timesteps\n",
        "t=np.linspace(0,5,nT+1)\n",
        "y=np.zeros(nT+1)\n",
        "y[0]=1.0\n",
        "h=t[1]-t[0]\n",
        "\n",
        "for j in range(1,nT+1):\n",
        "  y[j]=forwardEuler(y[j-1],fun,h,t[j-1])\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(t,y,'-b')\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "1Ar9goequ6Rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can compare this numerical solution to the analytical solution, $y(t)=e^t$, using the same timesteps as the approximation.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qa4AiY3NuA5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ytrue=np.exp(t)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(t,y,'-b',t,ytrue,'g')\n",
        "plt.grid()\n"
      ],
      "metadata": {
        "id": "soaFH1H0zDIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the Forward Euler method grossly underestimates the solution. Computing the absolute error, we see that the error is also growing in time:\n"
      ],
      "metadata": {
        "id": "FktstZGSzuIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ytrue=np.exp(t)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(t,y,'-b',t,ytrue,'g',t,abs(y-ytrue),':r')\n",
        "plt.grid()\n"
      ],
      "metadata": {
        "id": "6D4fwXlFz6y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, if we run the simulation with a smaller stepsize $h$, we can have a more accurate solution. We do this in the code by increasing the number of timesteps within this interval. Increasing to 20 timesteps in the interval of [0,5], we see a decrease in the error "
      ],
      "metadata": {
        "id": "wS81kStZ0SlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nT=20 #number of timesteps\n",
        "t=np.linspace(0,5,nT+1)\n",
        "y=np.zeros(nT+1)\n",
        "y[0]=1.0\n",
        "h=t[1]-t[0]\n",
        "\n",
        "ytrue=np.exp(t)\n",
        "\n",
        "for j in range(1,nT+1):\n",
        "  y[j]=forwardEuler(y[j-1],fun,h,t[j-1])\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(t,y,'-b',t,ytrue,'g',t,abs(y-ytrue),':r')\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "0wZ2b50dzX_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Increasing to 500 timesteps we see an even more accurate solution."
      ],
      "metadata": {
        "id": "s0UpQ17H04jG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nT=500 #number of timesteps\n",
        "t=np.linspace(0,5,nT+1)\n",
        "y=np.zeros(nT+1)\n",
        "y[0]=1.0\n",
        "h=t[1]-t[0]\n",
        "\n",
        "ytrue=np.exp(t)\n",
        "\n",
        "for j in range(1,nT+1):\n",
        "  y[j]=forwardEuler(y[j-1],fun,h,t[j-1])\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(t,y,'-b',t,ytrue,'g',t,abs(y-ytrue),':r')\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "IhRchblv0pcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nJkzYg_8ueLw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercises\n",
        "\n",
        "1. Adjust ``fun`` for the function $f(t,y)=y-t^2+1$ and use Forward Euler code to find the approximation for the interval $[0,2]$, with $h=0.2$ and $y(0)=0.5$. Compare the approximation with the solution $y=(t+1)^2-0.5e^t$.\n",
        "\n",
        "2. Adjust ``fun`` for the function $f(t,y)=1+y/t$ and use Forward Euler code to find the approximation for the interval $[1,2]$, with $h=0.25$ and $y(1)=2$. \n",
        "Compare the approximation with the solution $y=2t+t\\log(t)$.\n",
        "\n",
        "3. Adjust ``fun`` for the function $f(t,y)=\\cos(2t)+\\sin(2t)$ and use Forward Euler to find the approximation for the interval $[0,1]$, with $h=0.25$ and $y(0)=1$. Compare the approximation with the solution $y=\\frac{1}{2}\\sin(2t)-\\frac{1}{3}\\cos(3t)+4/3$.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-Tp884AYoYJz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Error\n",
        "\n",
        "Note that in all of these cases, the error is still growing. Well there are two factors involved with this. \n",
        "\n",
        "One stems from using the forward difference approximation for the derivative. Assuming that $y(t_i)=y_i$, we can see that the method also emerges from taking a Taylor series of $y(t_{i+1})=y(t_i+h)$ centered at $a=t_i$\n",
        "\n",
        "$$y(t_{i}+h)=y(t_{i})+h y'(t_i)+h^{2}{f''(\\xi)\\over2}=y_i+hf(t_i,y_i)+O(h^2), \\qquad \\xi\\in[t_{i},t_{i}+h]$$\n",
        "\n",
        "So we see that Forward Euler encompasses the first two terms of the Taylor series. \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1WgZ063b1DY1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Local Error\n",
        "\n",
        "Taking the absolute difference between the solution and the Forward Euler approximation\n",
        "\n",
        "$$|y(t_i+h)-(y_{i}+hf(t_i,y_i))|=|y(t_i+h)-(y(t_{i})+hy(t_i))|=|O(h^{2})|=O(h^2)=Ch^{2}$$\n",
        "\n",
        "we say that Forward Euler has a second order, e.g. $O(h^2)$, local error.\n"
      ],
      "metadata": {
        "id": "GC-Yr7lk0rRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h=.1 #number of timesteps\n",
        "y[0]=1.0\n",
        "\n",
        "ytrue=np.exp(h)\n",
        "\n",
        "y[1]=forwardEuler(y[0],fun,h,t[0])\n",
        "\n",
        "print('Timestep is: '+str(h))\n",
        "print('Local error is: '+str(abs(ytrue-y[1])))"
      ],
      "metadata": {
        "id": "LOfBQyNK0uY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global Error\n",
        "\n",
        "Though Forward Euler is locally second order, we usually say it is (globally) first order. Though Forward Euler may have second order local error, remember that we are summing up these errors over a time interval. Assuming that the interval that we're summing over is $[0,T]$ then the number of subintervals we're advancing our solution over is $N=(T-0)/h={T\\over h}$.\n",
        "\n",
        "\n",
        "If we're looking to advance a solution from an initial value $y(0)=y_0$ to the value $y(T)$ over $N$ subintervals, then we can think of the solution as a sum of forward difference approximations with a local error of $Ch^2$. Summing up the error gives something known as global error,\n",
        "\n",
        "$$\\sum_{1}^{N}O(h^{2})=\\sum_{1}^{N}Ch^{2}=N\\cdot Ch^{2}={T/h}\\cdot Ch^2=TCh=O(h).$$\n",
        "\n",
        "We see that Forward Euler has a first order, global error. Global error is usually one order less than the local error, since it is the sum of errors. "
      ],
      "metadata": {
        "id": "uOCKuAYjq52V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h=.2 \n",
        "T=1.0\n",
        "nT=int(T/h) #number of timesteps\n",
        "t=np.linspace(0,1,nT+1)\n",
        "y=np.zeros(nT+1)\n",
        "y[0]=1.0\n",
        "\n",
        "ytrue=np.exp(T)\n",
        "\n",
        "for j in range(1,nT+1):\n",
        "  y[j]=forwardEuler(y[j-1],fun,h,t[j-1])\n",
        "\n",
        "print('Timestep is: '+str(h))\n",
        "print('Global error is: '+str(abs(ytrue-y[nT])))"
      ],
      "metadata": {
        "id": "tAt7bhgO2G6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercises\n",
        "\n",
        "1. To find local error, let's compare the error after one timestep, $t[1]$, with a known solution. For ${dy\\over dt}=y, y(0)=1$, we can use the true solution $y(t)=e^t$. Set $h=0.1$ for the Forward Euler approximation and compare it with the true solution after one timestep. Compare with $h=0.05$ and comment on how it changes. What is the ratio between the error for $h=0.1$ and the error for $h=0.05$.\n",
        "\n",
        "\n",
        "2.  To find global error, let's compare the error after all timesteps, $t[-1]$, with a known solution. For ${dy\\over dt}=y, y(0)=1$, we can use the true solution $y(t)=e^t$. Set $h=0.1$ for the Forward Euler approximation and compare it with the true solution at T=1.0. Compare with $h=0.05$ and comment on how it changes. What is the ratio between the error for $h=0.1$ and the error for $h=0.05$.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZVcz6ei6ubV9"
      }
    }
  ]
}