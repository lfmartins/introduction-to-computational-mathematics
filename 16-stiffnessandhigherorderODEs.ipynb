{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOgdsd+cqTnk/22IS441oR1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lfmartins/introduction-to-computational-mathematics/blob/main/16-stiffnessandhigherorderODEs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stiff Problems\n",
        "\n",
        "Many times when talking about stability of our methods, we talk about the stiffness of a system of equations. The formal definition of stiffness is a bit vague but generally the idea is asking how small of a timestep do we need to take to have a stable numerical solution.\n",
        "\n",
        "For instance\n",
        "\n",
        "$$y'= -y,\\qquad t\\in[a,b]$$\n",
        "\n",
        "is a simple ODE that can give solutions that are not converging to the correct answer if the tolerances are set too high.\n"
      ],
      "metadata": {
        "id": "G_5ZkSc0q4yO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.integrate import solve_ivp\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def fun1(t,y):\n",
        "    f=-1*y\n",
        "    return f\n",
        "\n",
        "sol0=solve_ivp(fun1,[0,10],[1],rtol=.01)\n",
        "sol1=solve_ivp(fun1,[0,10],[1],rtol=.1)\n",
        "sol2=solve_ivp(fun1,[0,10],[1],rtol=1)\n",
        "sol3=solve_ivp(fun1,[0,10],[1],rtol=2)\n",
        "\n",
        "plt.plot(sol0.t,sol0.y[0,:],sol1.t,sol1.y[0,:],sol2.t,sol2.y[0,:],sol3.t,sol3.y[0,:])"
      ],
      "metadata": {
        "id": "9qgRKzfPq-0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generally, there is a rule that\n",
        "\n",
        "$$y'=\\lambda y,\\qquad t\\in[t_0,t_N]$$\n",
        "\n",
        "required a small time step for Forward Euler generally if $(t_N-t_0)Re(\\lambda)<<-1$. This is due to the rapid decay of the system. \n",
        "\n",
        "For systems\n",
        "$$\\mathbf{y}'=\\mathbf{f}(\\mathbf{y},t)$$\n",
        "we can perform a similar analysis if we examine the Jacobian of the the system\n",
        "$$J=\\frac{\\partial \\mathbf{f}_i}{\\partial \\mathbf{y}_j}=\\begin{bmatrix} {\\partial f_1\\over\\partial y_{1}} & {\\partial f_1\\over\\partial y_{2}}\\\\\n",
        "{\\partial f_2\\over\\partial y_{1}} & {\\partial f_2\\over\\partial y_{2}}\n",
        "\\end{bmatrix}$$\n",
        "where $i$ stands for the row of the Jacobian and $j$ stands for the column of the Jacobian. We can make the argument that a system is stiff if\n",
        "\n",
        "$(t_N-t_0)\\min_{j}(Re(\\lambda_{j}))<<-1$\n",
        "\n",
        "where $\\lambda_{j}$ is an eigenvalue of the Jacobian. This can be found using eigen solve present in `numpy.linalg`.\n"
      ],
      "metadata": {
        "id": "xlAQpYHFrMCh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example \n",
        "Let's check out the stiffness of the Lotka Volterra equations. Our first step is to calculate the Jacobian of the system.\n",
        "\n",
        "We're going to first rewrite our variables $X$ and $Y$ as $y_1$ and $y_2$ to correspond to how we wrote out our stiff formulation\n",
        "\n",
        "$$y_1'=ay_1-b y_1 y_2=f_1(t,y_1,y_2),\\qquad y_1(0)=y_{1,0}$$\n",
        "$$y_2'=c y_1 y_2 - dy_2=f_2(t,y_1,y_2),\\qquad y_2(0)=y_{2,0}$$\n",
        "\n",
        "where $a=1.5$, $b=1$, $c=0.1$, and $d=1$. Now let's take a partial derivative of $f_1$ and $f_2$ (i.e. take a derivative with respect to only the variable in the numerator of ${df_i\\over dy_j}$ and treat all other variables as constants.\n",
        "\n",
        "$${\\partial f_1\\over \\partial y_1}=a-b y_2$$\n",
        "$${\\partial f_1\\over \\partial y_2}=-b y_1$$\n",
        "$${\\partial f_2\\over \\partial y_1}=c y_2$$\n",
        "$${\\partial f_2\\over \\partial y_2}=c y_1-d$$\n",
        "\n",
        "So our Jacobian is\n",
        "\n",
        "$$J=\\begin{bmatrix} {\\partial f_1\\over\\partial y_{1}} & {\\partial f_1\\over\\partial y_{2}}\\\\\n",
        "{\\partial f_2\\over\\partial y_{1}} & {\\partial f_2\\over\\partial y_{2}}\n",
        "\\end{bmatrix}=\\begin{bmatrix} a-b y_2 & -b y_1\\\\\n",
        "cy_2 & cy_1-d\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "plugging in the given values of $a,$ $b,$ $c,$ and $d$, and choosing $y_1=40$ and $y_2=.1$ to correspond roughly to the solution during a period where a lot of changes are occurring (i.e. when either the prey populations are very high and the predator population is very low). This value was taken from looking the previous solution. The resulting Jacobian with these values is:\n",
        "\n",
        "$$J=\\begin{bmatrix} 38.5 & -40\\\\\n",
        "0.01 & 3\n",
        "\\end{bmatrix}.$$\n",
        "\n",
        "Below is code to show how to calculate the eigenvalue of the Jacobian."
      ],
      "metadata": {
        "id": "5-kbhvE1rSB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import eig\n",
        "\n",
        "y1=40\n",
        "y2=.1\n",
        "\n",
        "a=1.5\n",
        "b=1.\n",
        "c=0.1\n",
        "d=1.\n",
        "\n",
        "J = np.array([[a-b*y1, -b*y1], \n",
        "              [c*y2, c*y1-d]])\n",
        "print(J)\n",
        "w,v=eig(J)\n",
        "print('eigenvalue:', w)\n",
        "print('eigenvector', v)\n",
        "\n",
        "print('The smallest (real component) of the eigenvalues is:', np.min(np.real(w)))"
      ],
      "metadata": {
        "id": "a_H7ro0grJDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Higher Order ODEs\n",
        "\n",
        "The **order of an ODE** is determined by **the highest order derivative present in the equation.**\n",
        "\n",
        "So far we've been mostly dealing with **first-order ODEs**, where the highest order derivative present in the differential equation is of order 1, e.g. $dy/dt$, $dy/dx$, $y'$, etc.... \n",
        "\n",
        "However we did have one example that was a higher order ODE,\n",
        "\n",
        "$$m{d^2y\\over dt^2}+\\beta{dy\\over dt}+gy=0$$\n",
        "\n",
        "This ODE is second order because the highest order derivative is ${d^2y\\over dt^2}$. This is known as the spring-mass-damper equation.\n",
        "\n",
        "Previously, we had to get an ODE into normal form to use our numerical methods\n",
        "$${dy\\over dt}=f(t,y) \\qquad \\mbox{or} \\qquad y'=f(t,y)$$\n",
        "For a higher order ODE, the highest order derivative is kept alone on the left-hand side and everything else is on the right-hand side. \n",
        "$$y''=f(t,y,y')$$\n",
        "$$y'''=f(t,y,y',y'')$$\n",
        "$$...$$\n",
        "$$y^{(n)}=f(t,y',y'',...,y^{(n-1)})$$\n",
        "\n",
        "\n",
        "We can set up normal form for  the spring-mass-damper equation\n",
        "$$my''+\\beta y'+gy=0,$$\n",
        "first by isolating $y''$,\n",
        "$$â‡’ my''=-\\beta y'-gy$$\n",
        "then dividing by the constant $m$\n",
        "$$\\Rightarrow y''=-\\frac{\\beta}{m}y' -\\frac{g}{m}y$$\n",
        "so that we have a normal form\n",
        "$$\\Rightarrow y''=f(t,y,y')$$\n",
        "where we see $f(t,y,y')=-\\frac{\\beta}{m}y' -\\frac{g}{m}y$. \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RyWUhDE9sNoP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why are we doing this? We have methods that work for this normal form... but how do we deal with the second derivative? \n",
        "\n",
        "One trick is to treat $y$ and $y'$ as separate variables $y_1$ and $y_2$ respectively. With $y=y_1$ and $y'=y_2$, we can then say $y''=y'_2$\n",
        "\n",
        "$$ y''=-\\frac{\\beta}{m}y' -\\frac{g}{m}y$$\n",
        "$$\\Rightarrow  y_2'=-\\frac{\\beta}{m}y_2 -\\frac{g}{m}y_1$$\n",
        "\n",
        "We're still interested in a solution $y$, so we can update $y$ using the form \n",
        "$$y'_1=y_2$$, since this is equivalent to $y'=y'$\n",
        "\n",
        "Combining these two parts, we turned our second order ODE into a system of first order ODES,\n",
        "\n",
        "$$y'_1=y_2$$\n",
        "$$y'_2=-\\frac{\\beta}{m}y_2 -\\frac{g}{m}y_1$$\n",
        "\n",
        "We can use the methods learned in Lesson 14 for systems of ODES using the following form,\n",
        "\n",
        "$$y'_1=f_1(t,y_1,y_2)$$\n",
        "$$y'_2=f_2(t,y_1,y_2).$$\n",
        "\n",
        "Below we've chosen $m=1$, $\\beta=0.1$, and $g=.1$, with initial conditions $y=y_1=1.0$ and $y'=y_2=0.0$\n"
      ],
      "metadata": {
        "id": "8jwZZ0Qh8nWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.integrate import solve_ivp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def SMDEqn(t,Z):\n",
        "    m=1\n",
        "    beta=0.1\n",
        "    g=.1\n",
        "    y1,y2=Z\n",
        "    f1=y2\n",
        "    f2=-(beta/m)*y2-(g/m)*y1\n",
        "    return [f1,f2]\n",
        "\n",
        "sol = solve_ivp(SMDEqn, [0, 100], [1, 0],'RK45',rtol=1e-6)\n",
        "plt.plot(sol.t,sol.y[0,:],'-vb')"
      ],
      "metadata": {
        "id": "P9ADhZbHso9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generally the behavior of the system depends on the value of $\\beta^2-4mg$. In the previous example we had $\\beta^2-4mg<0$. We call such a system underdamped, where the solution resembles $y=e^{p_1t}(A\\cos(\\omega t)+B\\sin(\\omega t))$.\n",
        "\n",
        "###Exercises\n",
        "1. Rerun with values such that $\\beta^2-4mg>0$. Try also with initial conditions $y=1$ and $y'=0.1$. We call such a system overdamped, where the solution resembles $y=Ae^{p_1t}+Be^{p_2t}$.\n",
        "2. Rerun with values such that $\\beta^2-4mg=0$. Try also with initial conditions $y=1$ and $y'=0.1$. We call such a system critically damped, where the solution resembles $y=(A+Bt)e^{pt}$.\n",
        "3. Rerun with the original values but $\\beta=0$, where the solution resembles $y=A\\cos(\\omega t)+B\\sin(\\omega t)$."
      ],
      "metadata": {
        "id": "ydPXUy0OD2H1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nI6wtwbfDFJT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}