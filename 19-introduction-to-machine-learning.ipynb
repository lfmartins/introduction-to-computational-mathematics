{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fa76117-db5d-4970-9685-092e80f4fec6",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, we explore Machine Learning (ML) algorithms for data classification. In this kind of problems, the data is organized as follows:\n",
    "\n",
    "- An array `X` with a data point per row. We let $n_X$ be the number of data points, corresponding to the number of rows in `X`\n",
    "- For each datapoint, the values of observed _features_. The number of features is denoted bu $n_f$, and corresponds to the number of columns in `X`.\n",
    "- An array `y` of _labels_ or _targets_. Array `y` had $n_X$ rows. Entry `y[i]` represents the class to which data point $X[i]$ belongs.\n",
    "\n",
    "The goal of classification is to define a _model_ that can accurately predict to which class a data point belongs, based on the values of the observed features.\n",
    "\n",
    "We start by importing the tools we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7f628f-4c81-4fa1-ba7f-97486698e92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import datasets\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817531ce-c555-4533-8eb6-de4e0c14f91a",
   "metadata": {},
   "source": [
    "# The Iris Dataset\n",
    "\n",
    "For this example, we will use the Iris Dataset, which is a small dataset that is appropriate for experimentation with classification algorithms. For a detailed description of the datset, visit the following [Wikipedia article](https://en.wikipedia.org/wiki/Iris_flower_data_set)\n",
    "\n",
    "The Iris Dataset is provided as a \"toy dataset\" in the `sklearn` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5489f6e4-1990-484f-ba0c-b29dd125b716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris(as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cfc468-5beb-4ec6-a293-869b6dd04d1d",
   "metadata": {},
   "source": [
    "Let's take a peek at the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5516a7e-2bf5-4d51-9f90-14ea3a12e336",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a43f05-2ae5-40d8-8273-bf7e9b535404",
   "metadata": {},
   "source": [
    "Each row corresponds to an observed iris flower. The features observed are the first four columns of the data frame. The last column specifies the class to which each data point belongs.\n",
    "\n",
    "The data is also available as `numpy` arrays, which is helpful for ML algorithms.\n",
    "The `iris.data` array contains the features observed for each data point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc46009-c5ea-413a-a486-450a0cc24830",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07e536b-1d68-4a73-a333-a23b5b14f5f7",
   "metadata": {},
   "source": [
    "The `iris.target` array contains the labels associated to each data point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f29123-448d-4c35-ac61-636a79628bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36bb58b-540d-4973-aacc-41b9a451118e",
   "metadata": {},
   "source": [
    "The members `iris.feature_names` and `iris.target_names` contains the names of features and classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c87ad1-a840-48b0-a6c3-c739e98bf90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Feature names: {iris.feature_names}')\n",
    "print(f'Class names: {iris.target_names}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8d6a76-d52d-4c70-8b6f-f4b4902fe2ba",
   "metadata": {},
   "source": [
    "A detailed description of the data set is also available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ff7c81-14b2-4f71-951e-fec61db0e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c61871-3c68-4ec8-949c-f1e2be6afa73",
   "metadata": {},
   "source": [
    "To visualize the dataset, let's plot a scatter matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4664e8-847e-407c-bbc3-42d5ab023bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "pd.plotting.scatter_matrix(iris_data, c=iris.target)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eead6b-91c4-4e75-9054-3bc2c7fd4816",
   "metadata": {},
   "source": [
    "Looking at the plots, we can see tht the three classes seem to be well separated by the given features. We will now construct a neural network model to perform the classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560bc56c-0fe4-4801-9cf6-b81e18a99100",
   "metadata": {},
   "source": [
    "# Neural Network Model\n",
    "\n",
    "An _Artificial Neural Network_ (ANN) is a model originally designed to model the human brain. Although it is a crude model, it is remarkably useful for many ML tasks. When used for classification tasks, the network consists of:\n",
    "\n",
    "- An _input layer_, containing one node corresponding to each feature.\n",
    "- One or more _hidden layers_, that performs the computations associated to the classification task.\n",
    "- An _output layer_, with one node for each of the possible classes.\n",
    "\n",
    "The parameters of an ANN are the strengths of the links between nodes. A detailed description of ANNs is beyond what can be presented here, but some information is available at [this link](https://www.ibm.com/cloud/learn/neural-networks)\n",
    "\n",
    "To build a model for the iris classification task, we start by splitting the data set into a _training set_ and a _test set_. The training set is used to fit the ANN parameters, and the test set is used to evaluate how good the model is to make predictions. This is illustrated in the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18a10d1-7386-486b-9589-f41442a49b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    iris.data, iris.target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e685c855-441a-4e05-b249-eb8fac2e7161",
   "metadata": {},
   "source": [
    "This splits the data in two subsets, with the test set containing 20% of the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb74a0d3-fb5d-455b-b2cd-0aa4fc28c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd52aeef-9232-4129-8ece-d347a04dff43",
   "metadata": {},
   "source": [
    "To define the network, we use the `MLPRegressor` class from `sklearn`. (MLP stands for _multi-layer perceptron_, which is an alternate name for an ANN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0495ffb8-4848-4fa9-9898-30e2fe3c1f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes=[10, 5], max_iter=2000, random_state=42)\n",
    "model.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46cc046-62af-4958-9644-ba2f47cbc022",
   "metadata": {},
   "source": [
    "_Note_: you may receive a message regarding convergence of the algorithm. The results may still be usable, but increasing the value of `max_iter` can improve convergence.\n",
    "\n",
    "We are now ready to make predictions for the data. We will do that both for the training set and the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e63a9-e6e3-45d3-b36b-effa4266c4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = model.predict(test_data)\n",
    "for p, t in zip(predictions_test, test_labels):\n",
    "    print(p, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32d0561-1e95-4472-aa90-bfc29db341f2",
   "metadata": {},
   "source": [
    "We can see that our predictions are highly accurate. In the next code cell, we evaluate quantitatively the accuracy of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7781de6-18db-4b31-8714-035e1c222773",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = model.predict(train_data)\n",
    "train_score = accuracy_score(predictions_train, train_labels)\n",
    "print(f'Training set accuracy {train_score}')\n",
    "predictions_test = model.predict(test_data)\n",
    "test_score = accuracy_score(predictions_test, test_labels)\n",
    "print(f'Test set accuracy: {test_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f29c66e-30d1-4671-8cd5-3316a34b98a7",
   "metadata": {},
   "source": [
    "We can see that the accuracies are pretty high, both for the training set and the test set, but of comparable values. As expected the accuracy on the testing set is not as high as the accuracy on the training set. \n",
    "\n",
    "Another way to display the accuracy of the model, is to compute the _confusion matrix_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886321f0-8182-4e1b-8c82-a3254b019094",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(predictions_train, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa5a329-73fb-4bdd-a302-2acdf56fd278",
   "metadata": {},
   "source": [
    "The diagonal entries of the matrix are the number of correct classifications in each class, and the other entries represent incorrect classifications. For the testing set we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05746aca-c586-469f-bcd6-f6ad76227ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(predictions_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895f4f16-ef99-4703-97fb-655afa29655f",
   "metadata": {},
   "source": [
    "The fact that the classification is so remarkably good is a consequence of a simple data set with classes that are clearly delineated. We should not expect such consistence for a more complex data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b8adee-219c-4018-a0be-2a66a925e27d",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "Experiment with the configuration of the ANN in the call to the constructor `MLPClassifier` and compare the results you get for different configurations. The documentation for the constructor can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html)\n",
    "\n",
    "Here are some of the things that can be tried:\n",
    "\n",
    "- Experiment with the relative sizes of the training set and test set.\n",
    "- Change the number of hidden layers.\n",
    "- Change the number of neurons in each layer.\n",
    "- Try different activation functions. The default activation function is `relu`, which is zero for negative values and linear for positive values. Two other alternatives are `logistic` and `tanh`.\n",
    "- Try different optimization algorithms. `sgd` is a stochastic gradient descent algorithm, and `lbgfs` is a quasi-Newton method. The default is `adam`, which is a gradient-based optimizer.\n",
    "- Experiment with the `alpha` parameter. `alpha` is a regularization parameter. Regularization is a procedure used to prevent overfitting, and is described in [this link](https://www.simplilearn.com/tutorials/machine-learning-tutorial/regularization-in-machine-learning)\n",
    "- Experiment with the `learning_rate`, which determines the length of each step taken in the optimization algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653da803-be9b-49f8-83d4-4779c065d629",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
